{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNKIMlEDZ_Vw"
      },
      "source": [
        "# Interactive Beam\n",
        "\n",
        "In this notebook, we set up your development environment and work through a simple example using the [DirectRunner](https://beam.apache.org/documentation/runners/direct/). You can explore other runners with the [Beam Capatibility Matrix](https://beam.apache.org/documentation/runners/capability-matrix/).\n",
        "\n",
        "The expectation is that this notebook will help you explore the tutorial in a more interactive way.\n",
        "\n",
        "To learn more about Colab, see [Welcome to Colaboratory!](https://colab.sandbox.google.com/notebooks/welcome.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz6KSQ13_3Rr"
      },
      "source": [
        "# Setup\n",
        "\n",
        "First, you need to set up your environment, which includes installing `apache-beam` and downloading a text file from Cloud Storage to your local file system. We are using this file to test your pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOOk81Jj_yUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9308d16-b9c1-4dbb-f6bc-8b69b7b78287"
      },
      "source": [
        "# Run and print a shell command.\n",
        "def run(cmd):\n",
        "  print('>> {}'.format(cmd))\n",
        "  !{cmd}\n",
        "  print('')\n",
        "\n",
        "run('pip install --upgrade pip')\n",
        "\n",
        "# Install apache-beam.\n",
        "run('pip install --quiet apache-beam')\n",
        "\n",
        "# Copy the input file into the local file system.\n",
        "run('mkdir -p data')\n",
        "run('gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> pip install --upgrade pip\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.2)\n",
            "\n",
            ">> pip install --quiet apache-beam\n",
            "\n",
            ">> mkdir -p data\n",
            "\n",
            ">> gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt data/\n",
            "Copying gs://dataflow-samples/shakespeare/kinglear.txt...\n",
            "/ [1 files][153.6 KiB/153.6 KiB]                                                \n",
            "Operation completed over 1 objects/153.6 KiB.                                    \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c35B2XSSv0Rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3633753c-99a0-472e-889e-b96b43c7719f"
      },
      "source": [
        "! wc -l data/kinglear.txt\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5525 data/kinglear.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnRHHTI6RDAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821586d6-0629-4ef1-b20b-96e54dda37fd"
      },
      "source": [
        "\n",
        "! head -3 data/kinglear.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tKING LEAR\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUqfqWyMuIfR"
      },
      "source": [
        "import apache_beam as beam\n",
        "import re\n",
        "\n",
        "inputs_pattern = 'data/*'\n",
        "outputs_prefix = 'outputs/part'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4LZ-GwZ7yHO"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fntXsJh7y7b"
      },
      "source": [
        "## How to interactively work with Beam\n",
        "\n",
        "Here is an example of how to work iteratively with beam in order to understand what is happening in your pipeline.\n",
        "\n",
        "Firstly, reduce the size of the King Lear file to be manageable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA9P9WEe661s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2386fd7-65b6-48c7-8c7b-4de082cf2316"
      },
      "source": [
        "\n",
        "! head -10 data/kinglear.txt > data/small.txt\n",
        "! wc -l data/small.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 data/small.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbQtmvTF8I2A"
      },
      "source": [
        "Create a custom print function (the python3 function `print` is supposed to work but we define our own here). Then it is possible to see what you are doing to the file.\n",
        "\n",
        "But something is wrong... why is it printing twice, see [SO](https://stackoverflow.com/a/52282001/1185293)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRncM_GJ6Jsk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "953bedb1-c8a4-434a-b3bf-b2f408dc2126"
      },
      "source": [
        "def myprint(x):\n",
        "  print('{}'.format(x))\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  (pipeline\n",
        "      | 'Read lines' >> beam.io.ReadFromText('data/small.txt')\n",
        "      | \"print\" >> beam.Map(myprint)\n",
        "  )\n",
        "\n",
        "result = pipeline.run()\n",
        "result.wait_until_finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tKING LEAR\n",
            "\n",
            "\n",
            "\tDRAMATIS PERSONAE\n",
            "\n",
            "\n",
            "LEAR\tking of Britain  (KING LEAR:)\n",
            "\n",
            "KING OF FRANCE:\n",
            "\n",
            "\tKING LEAR\n",
            "\n",
            "\n",
            "\tDRAMATIS PERSONAE\n",
            "\n",
            "\n",
            "LEAR\tking of Britain  (KING LEAR:)\n",
            "\n",
            "KING OF FRANCE:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DONE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qecOY9oy-t_I"
      },
      "source": [
        "Now, let's break split each line on spaces and get the words out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTmuelL-p7-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d029c8-5fa4-46f0-e84c-5fd74cd6bc33"
      },
      "source": [
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  (pipeline\n",
        "      | 'Read lines' >> beam.io.ReadFromText('data/small.txt')\n",
        "      | 'get words' >> beam.FlatMap(lambda line: re.findall(r\"[a-zA-Z']+\", line))\n",
        "      | \"print\" >> beam.Map(myprint)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KING\n",
            "LEAR\n",
            "DRAMATIS\n",
            "PERSONAE\n",
            "LEAR\n",
            "king\n",
            "of\n",
            "Britain\n",
            "KING\n",
            "LEAR\n",
            "KING\n",
            "OF\n",
            "FRANCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1b1x1qT_x0y"
      },
      "source": [
        "Recall that `flatMap`s typically act on something (a function, iterable or variable) and apply a function to that something to produce a list of elements. See [this](https://beam.apache.org/documentation/transforms/python/elementwise/flatmap/) great example of how FlatMap works in Beam, and this answer on [SO](https://stackoverflow.com/a/45682977/1185293) for a simple explanation.\n",
        "\n",
        "In the case above, we applied an anonymous function (lambda function) to a line. We can define it explicitly if you prefer a more conventional syntax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp36rDbMASEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a641482c-b9fc-472f-fae3-2697c1cbbdb7"
      },
      "source": [
        "def my_line_split_func(line):\n",
        "  return re.findall(r\"[a-zA-Z']+\", line)\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  (pipeline\n",
        "      | 'Read lines' >> beam.io.ReadFromText('data/small.txt')\n",
        "      | 'get words' >> beam.FlatMap(my_line_split_func)\n",
        "      | \"print\" >> beam.Map(myprint)\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KING\n",
            "LEAR\n",
            "DRAMATIS\n",
            "PERSONAE\n",
            "LEAR\n",
            "king\n",
            "of\n",
            "Britain\n",
            "KING\n",
            "LEAR\n",
            "KING\n",
            "OF\n",
            "FRANCE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEcvVGs7A7Pn"
      },
      "source": [
        "### Tutorial\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv3p_48aA9jO"
      },
      "source": [
        "! echo -e 'r1c1,r1c2,2020/03/05\\nr2c1,r2c2,2020/03/23' > data/play.csv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C76uqodZBPUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "efa47e6b-82da-44a1-9e71-8bc81d806774"
      },
      "source": [
        "\n",
        "class Transform(beam.DoFn):\n",
        "\n",
        "  # Use classes to perform transformations on your PCollections\n",
        "  # Yield or return the element(s) needed as input for the next transform\n",
        "  def process(self, element):\n",
        "    yield element\n",
        "\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "  (pipeline\n",
        "      | 'Read lines' >> beam.io.ReadFromText('data/play.csv')\n",
        "      | 'format line' >> beam.ParDo(Transform())\n",
        "      | \"print\" >> beam.Map(myprint)\n",
        "  )\n",
        "\n",
        "\n",
        "result.wait_until_finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r1c1,r1c2,2020/03/05\n",
            "r2c1,r2c2,2020/03/23\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'DONE'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run('gsutil cp gs://bdt-beam/users_v.csv data/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UINGCS8PxLlO",
        "outputId": "962a253b-ed8c-4439-b42e-630b5a4791d5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> gsutil cp gs://bdt-beam/users_v.csv data/\n",
            "Copying gs://bdt-beam/users_v.csv...\n",
            "- [1 files][140.3 KiB/140.3 KiB]                                                \n",
            "Operation completed over 1 objects/140.3 KiB.                                    \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1"
      ],
      "metadata": {
        "id": "FWs0mUUibevf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the date format transformation function\n",
        "def transform_date_format(date_str):\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%Y/%m/%d').strftime('%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        return date_str\n",
        "\n",
        "# Define the address transformation function\n",
        "def transform_address(address_str):\n",
        "\n",
        "    return address_str.replace('-', ',')\n",
        "\n",
        "def process_user_data(row):\n",
        "    # Split by delimiter\n",
        "    user_data = row.split(',')\n",
        "\n",
        "    if len(user_data) == 6:\n",
        "        user_id, name, gender, age, address, date_joined = user_data\n",
        "\n",
        "        # Transform the date format\n",
        "        formatted_date = transform_date_format(date_joined)\n",
        "\n",
        "        # Transform the address format\n",
        "        formatted_address = transform_address(address)\n",
        "\n",
        "        # Combine data back into the required format with semicolon delimiter\n",
        "        return f'{user_id};{name};{gender};{age};{formatted_address};{formatted_date}'\n",
        "    return None\n",
        "\n",
        "def filter_valid_rows(row):\n",
        "    return row is not None\n",
        "\n",
        "with beam.Pipeline() as pipeline:\n",
        "    (\n",
        "        pipeline\n",
        "        | 'Read CSV' >> beam.io.ReadFromText('data/users_v.csv', skip_header_lines=1)\n",
        "        | 'Process Rows' >> beam.Map(process_user_data)\n",
        "        | 'Filter Invalid Rows' >> beam.Filter(filter_valid_rows)\n",
        "        | 'Write to CSV' >> beam.io.WriteToText('marketing_format.csv')\n",
        "    )\n"
      ],
      "metadata": {
        "id": "iQhg7WFCWNz4"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('marketing_format.csv-00000-of-00001')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOcuQdR2b3Af",
        "outputId": "6b0fcb4e-4186-4d31-e182-5987e3da79ea"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        1;Anthony Wolf;male;73;New Rachelburgh  VA  49583;2019-03-13\n",
            "0  2;James Armstrong;male;56;North Jillianfort  UT  86454;2020-11-06\n",
            "1               3;Cody Shaw;male;75;North Anne  SC  53799;2004-05-29\n",
            "2   4;Sierra Hamilton;female;76;New Angelafurt  ME  46190;2005-08-26\n",
            "3        5;Chase Davis;male;31;South Bethmouth  WI  18562;2018-04-30\n",
            "4         6;Sierra Andrews;female;21;Ryanville  MI  69690;2007-05-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2"
      ],
      "metadata": {
        "id": "nPRJoA6fbaxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam\n",
        "from datetime import datetime\n",
        "\n",
        "def transform_date_format(date_str):\n",
        "    try:\n",
        "        return datetime.strptime(date_str, '%Y/%m/%d').strftime('%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        return date_str\n",
        "\n",
        "def transform_address(address_str):\n",
        "    return address_str.replace('-', ',')\n",
        "\n",
        "def process_user_data(row):\n",
        "    user_data = row.split(',')\n",
        "\n",
        "    if len(user_data) == 6:\n",
        "        user_id, name, gender, age, address, date_joined = user_data\n",
        "\n",
        "        # Transform the date format\n",
        "        formatted_date = transform_date_format(date_joined)\n",
        "\n",
        "        # Transform the address format\n",
        "        formatted_address = transform_address(address)\n",
        "\n",
        "        # Extract state from the address for geographical analysis\n",
        "        state = formatted_address.split(',')[1] if ',' in formatted_address else 'Unknown'\n",
        "\n",
        "        return (user_id, name, gender, age, formatted_address, formatted_date, state)\n",
        "    return None\n",
        "\n",
        "# Function to get the gender count\n",
        "def get_gender_count(data):\n",
        "    gender_counts = {}\n",
        "    for _, _, gender, _, _, _ in data:\n",
        "        if gender in gender_counts:\n",
        "            gender_counts[gender] += 1\n",
        "        else:\n",
        "            gender_counts[gender] = 1\n",
        "    return gender_counts\n",
        "\n",
        "# Function to get customer count per day\n",
        "def get_customers_per_day(data):\n",
        "    day_counts = {}\n",
        "    for _, _, _, _, _, date in data:\n",
        "        if date in day_counts:\n",
        "            day_counts[date] += 1\n",
        "        else:\n",
        "            day_counts[date] = 1\n",
        "    return day_counts\n",
        "\n",
        "# Function to get customer count per state\n",
        "def get_customers_per_state(data):\n",
        "    state_counts = {}\n",
        "    for _, _, _, _, _, _, state in data:\n",
        "        if state in state_counts:\n",
        "            state_counts[state] += 1\n",
        "        else:\n",
        "            state_counts[state] = 1\n",
        "    return state_counts\n",
        "\n",
        "# Pipeline\n",
        "with beam.Pipeline() as pipeline:\n",
        "    user_data = (\n",
        "        pipeline\n",
        "        | 'Read CSV' >> beam.io.ReadFromText('data/users_v.csv')\n",
        "        | 'Process Rows' >> beam.Map(process_user_data)\n",
        "        | 'Filter Invalid Rows' >> beam.Filter(lambda row: row is not None)\n",
        "    )\n",
        "\n",
        "    # Gender Composition\n",
        "    gender_composition = (\n",
        "        user_data\n",
        "        | 'Extract Gender' >> beam.Map(lambda row: (row[2]))\n",
        "        | 'Count Gender' >> beam.combiners.Count.PerElement()\n",
        "        | 'Format Gender Output' >> beam.Map(lambda x: f'Gender: {x[0]}, Count: {x[1]}')\n",
        "    )\n",
        "\n",
        "    # Customers per Day\n",
        "    customers_per_day = (\n",
        "        user_data\n",
        "        | 'Extract Date' >> beam.Map(lambda row: (row[5]))\n",
        "        | 'Count Customers per Day' >> beam.combiners.Count.PerElement()\n",
        "        | 'Format Day Output' >> beam.Map(lambda x: f'Date: {x[0]}, Count: {x[1]}')\n",
        "    )\n",
        "\n",
        "    # Customers per State\n",
        "    customers_per_state = (\n",
        "        user_data\n",
        "        | 'Extract State' >> beam.Map(lambda row: (row[6]))\n",
        "        | 'Count Customers per State' >> beam.combiners.Count.PerElement()\n",
        "        | 'Format State Output' >> beam.Map(lambda x: f'State: {x[0]}, Count: {x[1]}')\n",
        "    )\n",
        "\n",
        "    # Write outputs to text files\n",
        "    gender_composition | 'Write Gender Composition' >> beam.io.WriteToText('gender_composition', file_name_suffix='.txt', shard_name_template='')\n",
        "    customers_per_day | 'Write Customers Per Day' >> beam.io.WriteToText('customers_per_day', file_name_suffix='.txt', shard_name_template='')\n",
        "    customers_per_state | 'Write Customers Per State' >> beam.io.WriteToText('customers_per_state', file_name_suffix='.txt', shard_name_template='')\n"
      ],
      "metadata": {
        "id": "6OoC0xkRZQKo"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('customers_per_day.txt')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37lFwkkSfryd",
        "outputId": "7bed9490-4240-4177-f85b-d71b95a840a5"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Date: date_joined   Count: 1\n",
            "0  Date: 2019-03-13   Count: 1\n",
            "1  Date: 2020-11-06   Count: 1\n",
            "2  Date: 2004-05-29   Count: 2\n",
            "3  Date: 2005-08-26   Count: 1\n",
            "4  Date: 2018-04-30   Count: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('customers_per_state.txt')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv-c0Lpqf5u0",
        "outputId": "ac4b563a-2492-4790-a29c-0ff0095896c3"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  State: Unknown    Count: 1\n",
            "0      State: VA   Count: 44\n",
            "1      State: UT   Count: 50\n",
            "2      State: SC   Count: 50\n",
            "3      State: ME   Count: 43\n",
            "4      State: WI   Count: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('gender_composition.txt')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AnCz16SgDcX",
        "outputId": "541a4619-bdf6-47aa-8601-607d6affb302"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Gender: gender      Count: 1\n",
            "0    Gender: male   Count: 1207\n",
            "1  Gender: female   Count: 1150\n"
          ]
        }
      ]
    }
  ]
}